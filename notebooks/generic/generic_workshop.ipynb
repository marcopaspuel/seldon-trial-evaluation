{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RomFuTAqSW0Z"
   },
   "source": [
    "# Iris Classification\n",
    "This notebook gets you hands-on with Seldon Deploy, demonstrating how you can deploy, monitor, manage and explain machine learning models. \n",
    "\n",
    "In this notebook you will:\n",
    "\n",
    "* Explore the Iris dataset\n",
    "* Train several models on the dataset\n",
    "* Deploy trained models to Seldon\n",
    "* Train an anchor tabular explainer and update Seldon deployment with this explainer\n",
    "* Train an outlier detector (variational autoencoder) and update deployment\n",
    "\n",
    "\n",
    "For each of the machine learning components (the models themselves, explainer and outlier detector) the workflow is the same: \n",
    "1. Train algorithm\n",
    "2. Push trained artefact to Google Storage bucket\n",
    "3. Create deployment on Seldon Deploy via API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01OHsBI6SW0e"
   },
   "source": [
    "### Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HfKXJ5t5SW0i",
    "outputId": "7e17866f-08ae-4b9c-e20c-21345c2f7dd9"
   },
   "outputs": [],
   "source": [
    "!pip install seldon-deploy-sdk\n",
    "!pip install alibi\n",
    "!pip install alibi-detect\n",
    "!pip install fsspec\n",
    "!pip install gcsfs\n",
    "!pip install dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5WGfR_7vSW0m"
   },
   "outputs": [],
   "source": [
    "from seldon_deploy_sdk import Configuration, ApiClient, SeldonDeploymentsApi, OutlierDetectorApi\n",
    "from seldon_deploy_sdk.auth import OIDCAuthenticator\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from alibi.explainers import AnchorTabular\n",
    "\n",
    "from alibi_detect.od import Mahalanobis\n",
    "from alibi_detect.datasets import fetch_kdd\n",
    "from alibi_detect.utils.data import create_outlier_batch\n",
    "from alibi_detect.utils.mapping import ord2ohe\n",
    "from alibi_detect.utils.saving import save_detector, load_detector\n",
    "from alibi_detect.utils.visualize import plot_instance_score, plot_roc\n",
    "\n",
    "import dill\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dMwu2Rk4SW0r"
   },
   "source": [
    "### Loading the data\n",
    "Once you have all of the relevant packages you can now explore the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MgWkzF1dSW0t"
   },
   "outputs": [],
   "source": [
    "dataset = load_iris()\n",
    "feature_names = dataset.feature_names\n",
    "class_names = list(dataset.target_names)\n",
    "\n",
    "X = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRia7-RuSW0v"
   },
   "source": [
    "Creating a train/test split of the data to ensure you have an unseen subset of the dataset with which to validate your model's performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4qIxSW-nSW0y"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F2b5qbHkSW00",
    "outputId": "56d4a750-689e-4312-fbb8-35d792f67bfa"
   },
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBAzFRZySW02"
   },
   "source": [
    "Inspecting a single instance (row) of your data, you can see that it is made up of four different numerical features:\n",
    "1. Sepal length\n",
    "2. Sepal width\n",
    "3. Petal length\n",
    "4. Petal width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nW3GSuqcSW04",
    "outputId": "02d3b846-87a6-4324-fd02-19db47ca291e"
   },
   "outputs": [],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dHfasBPrSW05"
   },
   "source": [
    "Meanwhile, the labels (your y data) have three separate classes- each representing a different species of Iris:\n",
    "\n",
    "0. Iris setosa\n",
    "1. Iris virginica\n",
    "2. Iris versicolor\n",
    "\n",
    "I wouldn't worry about remembering those names..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtm3VdPUSW06"
   },
   "source": [
    "### Model training\n",
    "Next you will train two separate machine learning models on your dataset. This is representative of the iterative process of algorithm creation which Data Scientists go through during the experimentation process. \n",
    "\n",
    "The first model is a logistic regressor which we train using the `.fit()` method, and then evaluate using the `accuracy_score()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WOiGalUqSW07",
    "outputId": "2c9c3de2-b47a-4bec-f093-eef05158f416"
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=4000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print(precision_score(y_test, lr.predict(X_test), average=\"macro\"))\n",
    "print(recall_score(y_test, lr.predict(X_test), average=\"macro\"))\n",
    "print(accuracy_score(y_test, lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MxWp8CGSW08"
   },
   "source": [
    "You'll notice that your model has perfect evaluation scores, this implies that the model is overfitted on the dataset. For the purposes of this workshop, you're not going to worry about this.\n",
    "\n",
    "----\n",
    "\n",
    "You can now train your second machine learning model- an XGBoost classifier. The first step is to convert the dataset into XGBoost's expected DMatrix data format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U2n7Rs61SW09"
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6dCVcUJSW09"
   },
   "source": [
    "Next, you will set the hyperparameters associated with the XGBoost algorithim. This is essentially telling the model how large to be (`max_depth`), how quickly to learn (`eta`), information about the task (`objective`) and  the number of classes (`num_class`). \n",
    "\n",
    "Finally, you set the `num_round` which tells XGBoost how many iterations over the dataset to perform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zCxOKjK1SW0-"
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.3,\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': 3} \n",
    "\n",
    "num_round = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHPU7o8HSW0-"
   },
   "source": [
    "You can then train and score the classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CPH0kxIiSW0-",
    "outputId": "eb992b87-8039-46a0-fe0b-fe1f8cd0fe66"
   },
   "outputs": [],
   "source": [
    "bst = xgb.train(param, dtrain, num_round)\n",
    "preds = np.asarray([np.argmax(line) for line in bst.predict(dtest)])\n",
    "print(precision_score(y_test, preds, average=\"macro\"))\n",
    "print(recall_score(y_test, preds, average=\"macro\"))\n",
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iml5FehYSW0_"
   },
   "source": [
    "Again, you can see that the model has overfit on the dataset. However, you will now save both of the models ready for them to be deployed. \n",
    "\n",
    "The Scikit-Learn pre-packaged server expects the saved model artefact to be called `model.joblib`. Meanwhile, the XGBoost pre-packaged server expects your model to be called `model.bst` when it is uploaded to our storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QA5ExihMSW0_"
   },
   "outputs": [],
   "source": [
    "# Saving the logistic regressor\n",
    "joblib.dump(lr, 'model.joblib')\n",
    "\n",
    "# Saving the XGBoost classifier\n",
    "bst.save_model('model.bst')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJI4NA4cSW1A"
   },
   "source": [
    "### Push model artefacts to GCP\n",
    "\n",
    "You will now push the saved model binaries to a GCP bucket, where they can be picked up by Seldon and deployed onto Kubernetes. \n",
    "\n",
    "You will need to create a unique name for your model artefact. It's easiest to just use your own name. Be careful not to use any upper-case letters or other characters like \"_\". Dashes are fine, so for example: YOUR_NAME = \"john-smith\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pY01jI5KHlwU"
   },
   "outputs": [],
   "source": [
    "YOUR_NAME = \"john-smith\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y_V5lgCkSW1A",
    "outputId": "db93b51e-ed00-44f4-c605-650dd7ad82ca"
   },
   "outputs": [],
   "source": [
    "!gsutil cp model.joblib gs://tom-seldon-examples/deploy-workshop/\"{YOUR_NAME}\"/lr/model.joblib\n",
    "!gsutil cp model.bst gs://tom-seldon-examples/deploy-workshop/\"{YOUR_NAME}\"/xgb/model.bst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qDRBvVzRSW1B"
   },
   "source": [
    "### Model Deployment\n",
    "\n",
    "Deploying the model to a Seldon Deploy trial instance using the `seldon-deploy-sdk`. \n",
    "\n",
    "First, setting up the configuration and authentication required to access the cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lf1mxpQmSW1B"
   },
   "outputs": [],
   "source": [
    "SD_IP = \"\"\n",
    "\n",
    "config = Configuration()\n",
    "config.host = f\"http://{SD_IP}/seldon-deploy/api/v1alpha1\"\n",
    "config.oidc_client_id = \"sd-api\"\n",
    "config.oidc_client_secret = \"sd-api-secret\"\n",
    "config.oidc_server = f\"http://{SD_IP}/auth/realms/deploy-realm\"\n",
    "\n",
    "def auth():\n",
    "    auth = OIDCAuthenticator(config)\n",
    "    config.access_token = auth.authenticate(\"admin@seldon.io\", \"12341234\")\n",
    "    api_client = ApiClient(config)\n",
    "    return api_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tM7MBe3FSW1C"
   },
   "source": [
    "Now we have configured the IP correctly as well as setup our authentication function we can describe the deployment we would like to create.\n",
    "\n",
    "You will need to fill in the DEPLOYMENT_NAME, NAMESPACE, and the MODEL_LOCATION, the rest of the deployment description has been templated for you.\n",
    "\n",
    "We fill first deploy the logistic regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iMC5dC7xSW1D"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"lr\"\n",
    "\n",
    "DEPLOYMENT_NAME = f\"{YOUR_NAME}-{MODEL_NAME}\"\n",
    "MODEL_LOCATION = f\"gs://tom-seldon-examples/deploy-workshop/{YOUR_NAME}/{MODEL_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oSib6ZcZSW1D"
   },
   "outputs": [],
   "source": [
    "NAMESPACE = \"test\"\n",
    "PREPACKAGED_SERVER = \"SKLEARN_SERVER\"\n",
    "\n",
    "CPU_REQUESTS = \"1\"\n",
    "MEMORY_REQUESTS = \"1Gi\"\n",
    "\n",
    "CPU_LIMITS = \"1\"\n",
    "MEMORY_LIMITS = \"1Gi\"\n",
    "\n",
    "mldeployment = {\n",
    "    \"kind\": \"SeldonDeployment\",\n",
    "    \"metadata\": {\n",
    "        \"name\": DEPLOYMENT_NAME,\n",
    "        \"namespace\": NAMESPACE,\n",
    "        \"labels\": {\n",
    "            \"fluentd\": \"true\"\n",
    "        }\n",
    "    },\n",
    "    \"apiVersion\": \"machinelearning.seldon.io/v1alpha2\",\n",
    "    \"spec\": {\n",
    "        \"name\": DEPLOYMENT_NAME,\n",
    "        \"annotations\": {\n",
    "            \"seldon.io/engine-seldon-log-messages-externally\": \"true\"\n",
    "        },\n",
    "        \"protocol\": \"seldon\",\n",
    "        \"transport\": \"rest\",\n",
    "        \"predictors\": [\n",
    "            {\n",
    "                \"componentSpecs\": [\n",
    "                    {\n",
    "                        \"spec\": {\n",
    "                            \"containers\": [\n",
    "                                {\n",
    "                                    \"name\": f\"{DEPLOYMENT_NAME}-container\",\n",
    "                                    \"resources\": {\n",
    "                                        \"requests\": {\n",
    "                                            \"cpu\": CPU_REQUESTS,\n",
    "                                            \"memory\": MEMORY_REQUESTS\n",
    "                                        },\n",
    "                                        \"limits\": {\n",
    "                                            \"cpu\": CPU_LIMITS,\n",
    "                                            \"memory\": MEMORY_LIMITS\n",
    "                                        }\n",
    "                                    }\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                \"name\": \"default\",\n",
    "                \"replicas\": 1,\n",
    "                \"traffic\": 100,\n",
    "                \"graph\": {\n",
    "                    \"implementation\": PREPACKAGED_SERVER,\n",
    "                    \"modelUri\": MODEL_LOCATION,\n",
    "                    \"name\": f\"{DEPLOYMENT_NAME}-container\",\n",
    "                    \"endpoint\": {\n",
    "                        \"type\": \"REST\"\n",
    "                    },\n",
    "                    \"parameters\": [],\n",
    "                    \"children\": [],\n",
    "                    \"logger\": {\n",
    "                        \"mode\": \"all\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"status\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U60-n9u1SW1E",
    "outputId": "202324fb-23e4-4565-d085-df3565bdb8d6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deployment_api = SeldonDeploymentsApi(auth())\n",
    "deployment_api.create_seldon_deployment(namespace=NAMESPACE, mldeployment=mldeployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvF85kJmSW1F"
   },
   "source": [
    "Our model should now be running as a fully fledged microservice. You can now log into Seldon Deploy and test your deployment:\n",
    "\n",
    "* URL: http://SD_IP/seldon-deploy/\n",
    "* Username: admin@seldon.io\n",
    "* Password: 12341234\n",
    "\n",
    "You can now test your model with this request.\n",
    "```\n",
    "{\n",
    "    \"data\": {\n",
    "    \"names\": [\"Sepal length\",\"Sepal width\",\"Petal length\", \"Petal Width\"],\n",
    "    \"ndarray\": [\n",
    "        [6.8,  2.8,  4.8,  1.4]\n",
    "    ]\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Next, you will add your XGBoost model as a canary and promote that to be the main predictor through the UI. Make sure to select 'XGBoost' as the runtime and use the following model artefact address:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"gs://tom-seldon-examples/deploy-workshop/{YOUR_NAME}/{MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExvflvoPSW1F"
   },
   "source": [
    "# Adding a Model Explainer\n",
    "\n",
    "Next, we shall train an explainer to glean deeper insights into the decisions being made by our model. We will make use of the [Anchors algorithm](https://docs.seldon.io/projects/alibi/en/stable/methods/Anchors.html), which has a production grade implementation available using the Seldon Alibi Explain library.\n",
    "\n",
    "The algorithm provides model-agnostic (black box) and human interpretable explanations suitable for classification models applied to images, text and tabular data. The idea behind anchors is to explain the behaviour of complex models with high-precision rules called anchors. These anchors are locally sufficient conditions to ensure a certain prediction with a high degree of confidence. Anchor algorithms incorporate coverage, which is the region the explanation applies within and are optimised to maximize coverage.\n",
    "\n",
    "As an example of anchors for tabular data, if we want to predict whether a person makes less or more than £50,000 per year based on the person’s characteristics including age (continuous variable) and marital status (categorical variable), then the following would be a potential anchor: Hugo makes more than £50,000 because he is married and his age is between 35 and 45 years.\n",
    "\n",
    "The first step will be to write a simple prediction function which the explainer can call in order to query our logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oycUUgaiSW1G"
   },
   "outputs": [],
   "source": [
    "predict_fn = lambda x: lr.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZcKCtnwSW1G"
   },
   "source": [
    "Now, define and fit the AnchorTabular explainer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zp81TwebSW1G",
    "outputId": "cc79ef19-8e23-46f6-954f-869bdb2fcdde"
   },
   "outputs": [],
   "source": [
    "explainer = AnchorTabular(predict_fn, feature_names)\n",
    "explainer.fit(X_train, disc_perc=(25, 50, 75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3FrHaIVCSW1H"
   },
   "source": [
    "Predicting the first instance within the test set, and consequently generating an explanation for that prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fscujWkSSW1H",
    "outputId": "f0ccb312-721f-449d-d8d9-c4e55a59a488"
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "print('Prediction: ', class_names[explainer.predictor(X_test[idx].reshape(1, -1))[0]])\n",
    "\n",
    "explanation = explainer.explain(X_test[idx], threshold=0.95)\n",
    "print('Anchor: %s' % (' AND '.join(explanation.anchor)))\n",
    "print('Precision: %.2f' % explanation.precision)\n",
    "print('Coverage: %.2f' % explanation.coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ztnYkhmLSW1H",
    "outputId": "9ce86c0e-71d4-4c52-a70c-9b6e78e9c4e2"
   },
   "outputs": [],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "laqX0JxrSW1I"
   },
   "source": [
    "Save the explainer. Your explainer must be saved as `explainer.dill` as once again Seldon Deploy will look for this artefact within a top level directory. \n",
    "\n",
    "NOTE: Dill is used to serialise the object instead of pickle as it offers a greater flexibilty in the object types which can be serialised. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDDra_eISW1I"
   },
   "outputs": [],
   "source": [
    "dill.dump(explainer, open( \"explainer.dill\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUkaupCOSW1I"
   },
   "source": [
    "Uploading the explainer to a Google Storage bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1LAeqUV5SW1J",
    "outputId": "da539114-7061-471e-f540-89e11ec2616e"
   },
   "outputs": [],
   "source": [
    "!gsutil cp explainer.dill gs://tom-seldon-examples/deploy-workshop/{YOUR_NAME}/lr/explainer.dill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UJCBp41SW1J"
   },
   "source": [
    "We will not update our deployment with the model trained in this notebook as Alibi Explain requires explainers to be trained within a Python 3.6.1 environment which Google Colab currently does not offer. We'll use a pretrained model instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O9Mm-zCRSW1J"
   },
   "outputs": [],
   "source": [
    "EXPLAINER_TYPE = \"AnchorTabular\"\n",
    "EXPLAINER_URI = f\"gs://tom-seldon-examples/deploy-workshop/pretrained\"\n",
    "\n",
    "explainer_spec = {\n",
    "                    \"type\": EXPLAINER_TYPE,\n",
    "                    \"modelUri\": EXPLAINER_URI,\n",
    "                    \"containerSpec\": {\n",
    "                        \"name\": \"\",\n",
    "                        \"resources\": {}\n",
    "                    }\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bQQC-xFQSW1K",
    "outputId": "a1081ade-75a0-489a-dbe4-1a6b6d72f356"
   },
   "outputs": [],
   "source": [
    "mldeployment['spec']['predictors'][0]['explainer'] = explainer_spec\n",
    "mldeployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKgtLMr3SW1K"
   },
   "source": [
    "Finally, creating our new deployment with the explainer added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jISzlnLsSW1K",
    "outputId": "2ea80f08-d362-4597-d7cb-a08dfe69cd7f"
   },
   "outputs": [],
   "source": [
    "deployment_api = SeldonDeploymentsApi(auth())\n",
    "deployment_api.create_seldon_deployment(namespace=NAMESPACE, mldeployment=mldeployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2ASDo87SW1L"
   },
   "source": [
    "# Outlier Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mz8abHEmSW1L"
   },
   "source": [
    "In this example you will make use of a Mahalanbois outlier detector. This algorithm calculates an outlier score, which is a measure of distance from the center of the features distribution (Mahalanobis distance). The Mahalanobis distance is focused on the idea of measuring how many standard deviations away your data point is from the mean of the distribution. \n",
    "\n",
    "The Mahalanobis outlier detector is an online detector, meaning that it has a running mean and covariance matrix with which it compares the new data points with to classify as outliers or not. It is online in the sense that each new data point contributes to this running mean and covariance matrix.\n",
    "\n",
    "The first step is to initialise your outlier detector. There are 4 parameters which will be critical to the performance of your outlier detector: \n",
    "* `threshold`: The distance threshold above which your data instance is flagged as an outlier. To begin with you can leave this blank and infer a given threshold later when fitting your detector to the dataset. \n",
    "* `n_components`: The number of components to use within the PCA. PCA is used to reduce the number of feature dimensions. This will make it easier to compute the Mahalanbois calculation especially on high feature datasets. \n",
    "* `std_clip`: Feature-wise standard deviation used to clip the observations before updating the mean and covariance matrix. \n",
    "* `start_clip`: Number of observations before clipping is applied.\n",
    "\n",
    "If your data has categorical features then these can be specified using the `cat_vars` parameter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIhpaPnHSW1L"
   },
   "source": [
    "Firstly, you will set the `n_components` value. The simplest way to set this value is using `n_components == min(n_samples, n_features)` and then scaling down if computational performance slows the computation of outliers.\n",
    "\n",
    "A more rigourous approach is demonstrated below. This essentially calculates the covariance matrix- how each feature varies with every other feature. This determines the eigenvalues and eigenvectors of the covariance matrix. \n",
    "\n",
    "The eigenvalues capture the variance of each component in the direction of the eigenvector. Therefore, you can use this to understand the contribution of each feature to the overall variance. From here you can make a determination of how many components to include in your PCA, as you now understand the contribution of each of the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fx2qyaINSW1M",
    "outputId": "1b79816b-1c1a-4a82-96b7-a7d28ca840dd"
   },
   "outputs": [],
   "source": [
    "mean, stdev = X_train.mean(axis=0), X_train.std(axis=0)\n",
    "cov_mat = np.cov((X_train - mean).T)\n",
    "cov_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h7zJKD58SW1O",
    "outputId": "125cc67a-71bd-466a-8185-c51c152d9523"
   },
   "outputs": [],
   "source": [
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "print(f'Eigenvectors \\n {eig_vecs}')\n",
    "print(f'Eigenvectors \\n {eig_vals}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rivk1Y4ESW1P",
    "outputId": "ba8dfb42-6005-41da-9621-841668537b77"
   },
   "outputs": [],
   "source": [
    "total = sum(eig_vals)\n",
    "var_exp = [(i / total)*100 for i in sorted(eig_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "\n",
    "print(\"Variance captured by each component:\")\n",
    "print(var_exp)\n",
    "print(80 * \"-\")\n",
    "print(\"Cumulative variance captured as we travel each component:\")\n",
    "print(cum_var_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uE7nd26_SW1S"
   },
   "source": [
    "From the above you can see that 91.9% of the variance is captured by a single component, therefore you could reasonably set `n_components = 1`. However, you gain an additional 5% points by including a second one, and therefore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "99vAd8prSW1S"
   },
   "outputs": [],
   "source": [
    "n_components = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7pUn1QTSW1T"
   },
   "source": [
    "`std_clip` is used to ensure that outliers do not impact the typical operation of the detector. If many, many outliers (e.g. in a DDoS attack, or multiple broken parts in a assembly line) were sent to the detector then the weights (covariance matrix) would shift to include these outliers, therefore we set a `std_clip` whereby any data points above this clip level will have their `stdev` clipped to this maximal value. \n",
    "\n",
    "Setting the `std_clip` is case by case dependent, but you will use the following heuristic to set it. You will look at the `stdev` across the features, selecting the one which is the most widely distributed (the highest value). You will then set the `std_clip` to be 2 stdevs away from this maximal value. \n",
    "\n",
    "The code snippet below illustrates this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0-V_rRnISW1U",
    "outputId": "c9989d4a-eae6-419d-eba6-d8dc589c736f"
   },
   "outputs": [],
   "source": [
    "std_clip = (2 * stdev.max(axis=0)).round(decimals=2)\n",
    "std_clip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQRD5flhSW1V"
   },
   "source": [
    "Finally, the `start_clip` value is used to \"warm up\" the outlier detector. When the detector is first initialised it can be sensitive to new observations- which lead to large changes in the online mean and covariance matrix. During this period of time you do not want to show the outlier detector any outliers as it can greatly skew the accuracy of the running mean and covariance matrix.\n",
    "\n",
    "Thus during this \"warm up\" period you only show the outlier detector examples of normal data, and do not perform any clipping. The `start_clip` value determines after which point you should begin clipping data points and introducing outliers into the mix. \n",
    "\n",
    "Therefore `start_clip` in this case will be equal to the length of `X_train`, as you know that there are no outlying data points within the original Iris dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qKhAbTsoSW1W",
    "outputId": "472dabab-b0ee-4dcc-d2fe-85f151938d1f"
   },
   "outputs": [],
   "source": [
    "start_clip = len(X_train)\n",
    "start_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ErgHKxKBSW1W",
    "outputId": "7da71478-08bc-4c60-dcf5-36316cdfe94a"
   },
   "outputs": [],
   "source": [
    "threshold = None\n",
    "\n",
    "od = Mahalanobis(threshold,\n",
    "                 n_components=n_components,\n",
    "                 std_clip=std_clip,\n",
    "                 start_clip=start_clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KlmnPM7VSW1X"
   },
   "source": [
    "If you were dealing with categorical variables you would now run `od.fit(...)` however because the Iris dataset is solely continuous variables you do not need to perform this step. \n",
    "\n",
    "------\n",
    "\n",
    "You do however now need to set the threshold of Mahalanobis distance above which you consider a data instance an outlier. This can be done using the convenient `infer_threshold()` method. \n",
    "\n",
    "You first create a synthetic outlier batch using your training data and labels, with a certain percentage of the batch as outliers. Based upon this percentage of outliers you shall update the threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RjJ572aASW1X",
    "outputId": "ecf16a2a-8ec4-4d73-f2b7-4c2729aab6d6"
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "perc_outlier = 5\n",
    "\n",
    "threshold_batch = create_outlier_batch(X_train, y_train, n_samples=1000, perc_outlier=perc_outlier)\n",
    "X_threshold, y_threshold = threshold_batch.data.astype('float'), threshold_batch.target\n",
    "X_threshold = (X_threshold - mean) / stdev\n",
    "print('{}% outliers'.format(100 * y_threshold.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIQvHu46SW1Y"
   },
   "source": [
    "Once you have created the synthetic data we can determine the threshold using `infer_threshold`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G6HwtZIpSW1Y",
    "outputId": "dff3443b-4a8c-4ab8-bfb5-1cdfacbd7839"
   },
   "outputs": [],
   "source": [
    "od.infer_threshold(X_threshold, threshold_perc=100-perc_outlier)\n",
    "print('New threshold: {}'.format(od.threshold))\n",
    "threshold = od.threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdKx3-6ySW1Z"
   },
   "source": [
    "You can now test your threshold by generating a second batch of outlying data, this time with a higher proportion of outliers: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aOTdqj1kSW1a",
    "outputId": "6e99fb14-eb03-4434-8520-31c8fd881b4e"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "outlier_batch = create_outlier_batch(X_train, y_train, n_samples=1000, perc_outlier=10)\n",
    "X_outlier, y_outlier = outlier_batch.data.astype('float'), outlier_batch.target\n",
    "X_outlier = (X_outlier - mean) / stdev\n",
    "print(X_outlier.shape, y_outlier.shape)\n",
    "print('{}% outliers'.format(100 * y_outlier.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZl7Z3xOSW1a"
   },
   "source": [
    "Generating outlier predictions from your new detector using the freshly created outlier batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wX2WglxTSW1a"
   },
   "outputs": [],
   "source": [
    "od_preds = od.predict(X_outlier, return_instance_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "Bt24SjTESW1b",
    "outputId": "e68f56f6-1166-492b-c285-75bafd686a16"
   },
   "outputs": [],
   "source": [
    "labels = outlier_batch.target_names\n",
    "y_pred = od_preds['data']['is_outlier']\n",
    "f1 = f1_score(y_outlier, y_pred)\n",
    "print('F1 score: {}'.format(f1))\n",
    "cm = confusion_matrix(y_outlier, y_pred)\n",
    "df_cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "sns.heatmap(df_cm, annot=True, cbar=True, linewidths=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "mflIqH2mSW1b",
    "outputId": "66c6c4a6-9202-4044-9757-42f53fc5d62a"
   },
   "outputs": [],
   "source": [
    "plot_instance_score(od_preds, y_outlier, labels, od.threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_85cO5sNSW1b"
   },
   "source": [
    "Saving your handiwork is simple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dkS4_y_wSW1c",
    "outputId": "02cac7e8-54bb-447f-d0f5-5835dbd4cb8e"
   },
   "outputs": [],
   "source": [
    "save_detector(od, \"outlier_detector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVlycFf_SW1c"
   },
   "source": [
    "Uploading the outlier detector to a Google Storage bucket.\n",
    "\n",
    "Make sure to replace `<YOUR NAME>` with your name to prevent overwriting others artefacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Biv60APDSW1e",
    "outputId": "3c4595be-f51d-4bc2-a5bb-273990701b3c"
   },
   "outputs": [],
   "source": [
    "# Recursive copy this time as the OD is saved as a directory containing all the relevant binaries and parameters.\n",
    "!gsutil cp -r outlier_detector gs://tom-seldon-examples/deploy-workshop/{YOUR_NAME}/lr/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEodBjJ6SW1i"
   },
   "outputs": [],
   "source": [
    "OD_URI = f'gs://tom-seldon-examples/deploy-workshop/{YOUR_NAME}/lr/outlier_detector/'\n",
    "OD_NAME = 'mahalobanis-od'\n",
    "\n",
    "od_config = {'deployment': DEPLOYMENT_NAME,\n",
    "             'deployment_namespace': NAMESPACE,\n",
    "             'namespace': 'seldon-logs',\n",
    "             'params': {'drift_batch_size': None,\n",
    "                        'env_secret_ref': None,\n",
    "                        'event_source': f'io.seldon.serving.dev-seldondeployment-{DEPLOYMENT_NAME}-outlier',\n",
    "                        'event_type': 'io.seldon.serving.inference.outlier',\n",
    "                        'http_port': '8080',\n",
    "                        'model_name': OD_NAME,\n",
    "                        'protocol': 'seldon.http',\n",
    "                        'reply_url': 'http://seldon-request-logger.seldon-logs',\n",
    "                        'storage_uri': OD_URI,\n",
    "                        'user_permission': None},\n",
    "             'prom_scraping': None,\n",
    "             'url': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3H4uXxdOSW1l",
    "outputId": "c6d477b1-9ddf-4e72-8a72-a9b6dcc59362",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "od_api = OutlierDetectorApi(auth())\n",
    "od_api.create_outlier_detector_seldon_deployment(name=DEPLOYMENT_NAME,\n",
    "                                                 namespace=NAMESPACE,\n",
    "                                                 outlier_detector=od_config)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "generic_workshop.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
